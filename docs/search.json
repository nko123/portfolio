[
  {
    "objectID": "dog_adoption.html",
    "href": "dog_adoption.html",
    "title": "Interactive Dog Adoption Application",
    "section": "",
    "text": "This interactive Python application, built in Jupyter Notebook, demonstrates fundamental programming concepts through a practical dog adoption and services platform. The application features user authentication, search functionality, and a dynamic booking system for various dog-related services."
  },
  {
    "objectID": "dog_adoption.html#project-overview",
    "href": "dog_adoption.html#project-overview",
    "title": "Interactive Dog Adoption Application",
    "section": "",
    "text": "This interactive Python application, built in Jupyter Notebook, demonstrates fundamental programming concepts through a practical dog adoption and services platform. The application features user authentication, search functionality, and a dynamic booking system for various dog-related services."
  },
  {
    "objectID": "dog_adoption.html#part-1-basic-authentication-and-search",
    "href": "dog_adoption.html#part-1-basic-authentication-and-search",
    "title": "Interactive Dog Adoption Application",
    "section": "Part 1: Basic Authentication and Search",
    "text": "Part 1: Basic Authentication and Search\n\nUser Login System\nThe first iteration implements a basic login system using lists to store usernames and passwords.\n\n# Login function\nuser_name = ['vbrad','nokwe','dadel','hjami']\nuser_password = ['brad123','okwe123','johnhancock1977','jami1234']\n\nlogin_username = input(\"Enter your username (Note: Case Sensitive): \")\nlogin_password = input(\"Enter your password (Note: Case Sensitive): \")\n\n# For loop to login\nfor n in user_name and user_password:\n  if login_username in user_name and login_password in user_password:\n    print(\"Login Successful\")\n    break\n  else:\n    print(\"Username or Password is wrong, Try again\")\n    break\n\n\n\nService Search Functionality\nUsers can search for available services using partial matching with the startswith() method and in operator.\n\nstuff = [\"Adopt a Dog\", \"Foster a Dog \", \"Donate a Dog\", \"Dog Therapy\",\n         \"Dog Yoga \", \"Dog Training\", \"Dog Grooming\",\"Dog Recipes\"]\n\nprint(\"Welcome to Woof Woof, a one stop for all things dogs!\")\n\nsearch_function = input(\"What Service are you looking for today: \")\nsearch_function = search_function.lower()\n\noptions_list = []\n\n# Using a for loop to search for a partial match in the list\nfor s in stuff:\n  s = s.lower()\n  m = s.startswith((search_function))\n  if m == True or search_function in s:\n    options_list.append(s)\n\n\n\nDisplaying Search Results\n\n# Check if anything was found\nif options_list == []:\n  print(f\"No results found with search\")\nelse:\n    print(f\"Here are results that match your search:\")\n    for index, op in enumerate(options_list):\n        new_index = index + 1\n        print(f\"{new_index}. {op}\")\n\n    num_stuff_selec = int(input(\"Select an option from the list: \"))\n    new_num_stuff_selec = int(num_stuff_selec) - 1\n\n    if new_num_stuff_selec &gt;= 0 and new_num_stuff_selec &lt; len(options_list):\n        print(f'You have chosen {num_stuff_selec} and want to view {options_list[new_num_stuff_selec]}')\n    else:\n        print(f'You have entered {num_stuff_selec}, which is not on the list.')"
  },
  {
    "objectID": "dog_adoption.html#part-2-enhanced-application-with-dictionary-based-data-structures",
    "href": "dog_adoption.html#part-2-enhanced-application-with-dictionary-based-data-structures",
    "title": "Interactive Dog Adoption Application",
    "section": "Part 2: Enhanced Application with Dictionary-Based Data Structures",
    "text": "Part 2: Enhanced Application with Dictionary-Based Data Structures\n\nUser Authentication with Dictionaries\nThe enhanced version uses nested dictionaries for more robust user authentication, mapping usernames to user details.\n\nuser_details = {\n    'vbrad': {'firstname':'valerie', 'lastname': 'bradley', 'password': 'brad123'},\n    'nokwe': {'firstname':'nkemdibe', 'lastname': 'okweye', 'password': 'okwe123'},\n    'dadel': {'firstname':'daniel', 'lastname': 'adelberg', 'password': 'johnhancock1977'},\n    'hjami': {'firstname':'hisham', 'lastname': 'jamil', 'password': 'jami1234'}\n}\n\n\n\nDog Database Structure\nA comprehensive database tracks dog information including breed, gender, age, availability status, and attributes.\n\ndog_database = {\n    'luna': {'breed':'husky', 'gender':'female', 'age': '12 months',\n             'status': 'available','attribute': 'good with kids'},\n    'rex': {'breed':'german shepherd', 'gender':'male', 'age': '6 months',\n            'status': 'available','attribute': 'good around other dogs'},\n    'prince': {'breed':'doberman', 'gender':'male', 'age': '2 years',\n               'status': 'unavailable','attribute': 'friendly'},\n    'daisy': {'breed':'goldendoodle', 'gender':'male', 'age': '2 years',\n              'status': 'available','attribute': 'energetic'},\n    'koda': {'breed':'samoyed', 'gender':'female', 'age': '4 months',\n             'status': 'unavailable','attribute': 'playful'},\n    'mona': {'breed':'husky', 'gender':'female', 'age': '7 months',\n             'status': 'available','attribute': 'nice'},\n    'lola': {'breed':'dalmation', 'gender':'female', 'age': '2 months',\n             'status': 'available','attribute': 'protective'}\n}\n\n\n\nEnhanced Login and Service Selection\n\nstuff = [\"Adopt a Dog\", \"Foster a Dog \", \"Dog Therapy\", \"Dog Yoga \",\n         \"Dog Training\", \"Dog Grooming\"]\n\noptions_list, avail_dog_database = [], []\n\n# Check if the user's name matches their password\nlogin_user = input(\"Enter your username (Note: Case Sensitive): \")\nlogin_pass = input(\"Enter your password (Note: Case Sensitive): \")\n\nfor user in user_details:\n  if login_user in user_details and login_pass == user_details[login_user]['password']:\n    print(\"Login Successful\")\n\n    print(f\"Welcome {user_details[login_user]['firstname']} {user_details[login_user]['lastname']} to Woof Woof, a one-stop for all things dogs!\")\n    search_function = input(\"What Service are you looking for today: \")\n    search_function = search_function.lower()\n\n    # Search for matching services\n    for s in stuff:\n      s = s.lower()\n      m = s.startswith((search_function))\n      if m == True or search_function in s:\n        options_list.append(s)\n        continue\n\n    if options_list != []:\n      print(f\"Here are results that match your search:\")\n\n      for index, op in enumerate(options_list):\n        new_index = index + 1\n        print(f\"{new_index}. {op}\")\n\n      num_stuff_selec = int(input(\"Select an option from the list: \"))\n      new_num_stuff_selec = int(num_stuff_selec) - 1\n\n      # Check if the number entered is valid\n      if new_num_stuff_selec &gt;= 0 and new_num_stuff_selec &lt; len(options_list):\n        print(f'You have chosen {num_stuff_selec} and want to view {options_list[new_num_stuff_selec]}')\n\n        print(f'Here are the dogs available:')\n        for dog in dog_database:\n          if dog_database[dog]['status'] == 'available':\n            avail_dog_database.append(dog)\n      else:\n        print(f'You have entered {num_stuff_selec}, which is not on the list.')\n        break\n    else:\n      print(f\"No results found with search\")\n  else:\n    print(\"Username or Password is wrong, Try again\")\n  break\n\n\n\nDog Adoption Process\nThis section handles the complete adoption workflow, including selection, confirmation, and status updates.\n\nif avail_dog_database != [] and options_list[new_num_stuff_selec] == \"adopt a dog\":\n  for i, adog in enumerate(avail_dog_database):\n    new_i = i + 1\n    print(f\"{new_i}. {adog}, {dog_database[adog]['breed']}, {dog_database[adog]['gender']}, {dog_database[adog]['age']}, {dog_database[adog]['attribute']}\")\n\n  num_avail_dog = int(input(\"Select a dog from the list: \"))\n  new_num_avail_dog = int(num_avail_dog) - 1\n\n  if new_num_avail_dog &gt;= 0 and new_num_avail_dog &lt; len(avail_dog_database):\n    print(f'You have chosen {avail_dog_database[new_num_avail_dog]}')\n\n    adopt_choice = input(\"Enter Yes to confirm adoptions and No to cancel: \")\n    adopt_choice = adopt_choice.lower()\n\n    if adopt_choice == \"yes\":\n      dog_database[avail_dog_database[new_num_avail_dog]]['status']='unavailable'\n\n      print(f'Your adoption process of {avail_dog_database[new_num_avail_dog]} is complete')\n      print(f\"{avail_dog_database[new_num_avail_dog]} status has now been updated to {dog_database[avail_dog_database[new_num_avail_dog]]['status']}\")\n    else:\n      print(f'Your adoption process of {avail_dog_database[new_num_avail_dog]} was not complete')\n  else:\n    print(f'You have entered {num_avail_dog}, which is not on the list')\n\n\n\nOther Services Booking\nThis section manages bookings for services like therapy, yoga, training, and grooming.\n\nif avail_dog_database != [] and options_list[new_num_stuff_selec] != \"adopt a dog\":\n    for i, adog in enumerate(avail_dog_database):\n        print(f\"{i+1}. {adog}, {dog_database[adog]['breed']}, {dog_database[adog]['gender']}, {dog_database[adog]['age']}, {dog_database[adog]['attribute']}\")\n\n    num_service_dog = int(input(\"Select a dog from the list for the service: \"))\n    new_num_service_dog = num_service_dog - 1\n\n    if new_num_service_dog &gt;= 0 and new_num_service_dog &lt; len(avail_dog_database):\n        selected_dog = avail_dog_database[new_num_service_dog]\n        print(f'You have chosen {selected_dog} for {options_list[new_num_stuff_selec]}.')\n\n        confirm_choice = input(\"Enter Yes to confirm and No to cancel: \").lower()\n        if confirm_choice == \"yes\":\n            dog_database[selected_dog]['status'] = 'unavailable'\n            print(f'{selected_dog} has been booked for {options_list[new_num_stuff_selec]}.')\n            print(f\"{avail_dog_database[new_num_service_dog]} status has now been updated to {dog_database[avail_dog_database[new_num_service_dog]]['status']}\")\n        else:\n            print(f'Your booking of {selected_dog} for {options_list[new_num_stuff_selec]} was not complete.')\n    else:\n        print(f'You have entered {num_service_dog}, which is not on the list.')"
  },
  {
    "objectID": "dog_adoption.html#key-programming-concepts-demonstrated",
    "href": "dog_adoption.html#key-programming-concepts-demonstrated",
    "title": "Interactive Dog Adoption Application",
    "section": "Key Programming Concepts Demonstrated",
    "text": "Key Programming Concepts Demonstrated\n\nData Structures\n\nLists: Used for storing usernames, passwords, and search results\nDictionaries: Nested dictionaries for user details and dog database\nList/Dictionary Manipulation: Adding, accessing, and modifying data\n\n\n\nControl Flow\n\nFor Loops: Iterating through lists and dictionaries\nConditional Statements: If/else logic for authentication and validation\nBreak Statements: Controlling loop execution\n\n\n\nFunctions and Methods\n\nString Methods: .lower(), .startswith()\nBuilt-in Functions: enumerate(), input(), print(), int()\nOperators: in operator for membership testing\n\n\n\nUser Interaction\n\nInput Validation: Checking if selections are within valid ranges\nConfirmation Workflows: Two-step process for critical actions\nStatus Updates: Real-time updates to database status fields"
  },
  {
    "objectID": "dog_adoption.html#technical-skills-showcased",
    "href": "dog_adoption.html#technical-skills-showcased",
    "title": "Interactive Dog Adoption Application",
    "section": "Technical Skills Showcased",
    "text": "Technical Skills Showcased\n\nPython fundamentals (loops, conditionals, functions)\nData structure implementation (lists, dictionaries)\nUser authentication systems\nSearch algorithms\nState management\nInput validation and error handling\nDynamic data updates\n\n← Back to Projects"
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About Me",
    "section": "Background",
    "text": "Background\nI’m a data professional with a passion for transforming complex data into actionable insights that drive business value. Currently pursuing my Master of Science in Data Science and Analytics at Georgetown University, I bring a unique blend of technical expertise and business acumen developed through my Honours Bachelor of Commerce in Business Technology Management from the University of Ottawa."
  },
  {
    "objectID": "about.html#professional-journey",
    "href": "about.html#professional-journey",
    "title": "About Me",
    "section": "Professional Journey",
    "text": "Professional Journey\nMy career has been shaped by meaningful experiences in government analytics and data engineering:\nAt the Department of National Defence, I worked as a Data Analyst where I:\n\nSupported data-driven decision-making for 200+ users across the department\nReduced report generation time by 40% through automated Power BI dashboards\nAchieved 95% positive feedback on delivered data products\nCut manual workflow processes by 25% through innovative Power Apps solutions\n\nAt Global Affairs Canada, as a Student Analyst, I:\n\nContributed to international policy reporting and analytics\nConducted competitive analyses to support strategic initiatives\nCollaborated with cross-functional teams to define meaningful metrics"
  },
  {
    "objectID": "about.html#what-drives-me",
    "href": "about.html#what-drives-me",
    "title": "About Me",
    "section": "What Drives Me",
    "text": "What Drives Me\nI’m passionate about:\n\nSolving Real Problems: Finding elegant technical solutions to complex business challenges\nData Storytelling: Translating complex analytics into clear, actionable insights\nContinuous Learning: Staying current with emerging technologies and methodologies\nCollaboration: Working with diverse teams to achieve shared goals"
  },
  {
    "objectID": "about.html#technical-philosophy",
    "href": "about.html#technical-philosophy",
    "title": "About Me",
    "section": "Technical Philosophy",
    "text": "Technical Philosophy\nI believe in building scalable, maintainable solutions that prioritize user needs. Whether it’s designing an intuitive dashboard, automating a repetitive workflow, or uncovering insights from data, I focus on creating value that lasts."
  },
  {
    "objectID": "about.html#education-growth",
    "href": "about.html#education-growth",
    "title": "About Me",
    "section": "Education & Growth",
    "text": "Education & Growth\nMy academic journey spans business technology and data science:\n\nCurrent: MS in Data Science & Analytics at Georgetown University (2025-2027)\n\nFocusing on advanced analytics, machine learning, and statistical methods\n\nCompleted: Honours BCom in Business Technology Management at University of Ottawa (2020-2025)\n\nBridged business strategy and technical implementation"
  },
  {
    "objectID": "about.html#beyond-work",
    "href": "about.html#beyond-work",
    "title": "About Me",
    "section": "Beyond Work",
    "text": "Beyond Work\nWhen I’m not analyzing data or building applications, I enjoy exploring new technologies, contributing to open-source projects, and staying active in the data science community."
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About Me",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’m always interested in discussing data science, analytics, technology, and opportunities to collaborate on meaningful projects.\nView My Projects → See My Skills →"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Department of National Defence\n\n\nDesigned and implemented an automated workflow system to streamline request tracking and management across the department.\n\n\n\n\nAutomated tracking of 100+ monthly requests\nReduced manual data entry by 80%\nDecreased task delays by 50%\nImproved visibility and accountability across teams\n\n\n\n\n\nAzure DevOps\nMicrosoft Forms\nMicrosoft Teams\nPower Automate\n\n\n\n\nThe portal significantly improved operational efficiency by eliminating manual tracking processes and providing real-time visibility into request status, enabling better resource allocation and faster response times."
  },
  {
    "objectID": "projects.html#professional-projects",
    "href": "projects.html#professional-projects",
    "title": "Projects",
    "section": "",
    "text": "Department of National Defence\n\n\nDesigned and implemented an automated workflow system to streamline request tracking and management across the department.\n\n\n\n\nAutomated tracking of 100+ monthly requests\nReduced manual data entry by 80%\nDecreased task delays by 50%\nImproved visibility and accountability across teams\n\n\n\n\n\nAzure DevOps\nMicrosoft Forms\nMicrosoft Teams\nPower Automate\n\n\n\n\nThe portal significantly improved operational efficiency by eliminating manual tracking processes and providing real-time visibility into request status, enabling better resource allocation and faster response times."
  },
  {
    "objectID": "projects.html#academic-personal-projects",
    "href": "projects.html#academic-personal-projects",
    "title": "Projects",
    "section": "Academic & Personal Projects",
    "text": "Academic & Personal Projects\n\n\n\nThe Menendez Brothers: From Courtrooms to Comments Sections\nGeorgetown University - DSAN 5000\n\nProject Subtitle\nThe Transformation of Menendez Media Narratives\n\n\nOverview\nOn August 20, 1989, Lyle and Erik Menendez shot and killed their parents in their Beverly Hills mansion. What followed was one of the most sensationalized criminal trials in American history. But the story didn’t end with their 1996 conviction—it evolved dramatically over 35 years, from tabloid sensation to Netflix phenomenon, from “cold-blooded killers” to potential victims of abuse deserving of freedom.\nThis data science project traces how public discourse around the Menendez brothers transformed across three decades and multiple media platforms, revealing fundamental shifts in how American society understands family violence, male victimization, and criminal justice.\n\n\nKey Features\n\nAnalysis of media narratives spanning 35 years (1989-2024)\nMulti-platform discourse analysis: traditional media, social media, and streaming content\nNatural language processing of public sentiment and narrative framing\nVisualization of evolving public perception over time\nExamination of societal shifts in understanding trauma and justice\n\n\n\nTechnologies Used\n\nPython\nNatural Language Processing (NLP)\nText Analysis & Sentiment Analysis\nData Visualization\nSocial Media Analytics\n\n\n\nResearch Questions\n\nHow has media framing of the Menendez case evolved from 1989 to 2024?\nWhat role did Netflix and social media play in reshaping public perception?\nHow do contemporary discussions reflect changing attitudes toward male victimization and family violence?\n\nView Project →\n\n\n\n\n\n\nA Deep Dive into U.S. Airline Performance\nGeorgetown University\n\nOverview\nAn immersive exploration of aviation data, uncovering hidden patterns in flight operations, delays, and travel trends through statistical modeling and interactive visualizations. This project transforms thousands of flight records into actionable insights about air travel dynamics.\n\n\nKey Features\n\nComprehensive analysis of U.S. airline performance metrics\nInteractive visualizations revealing flight delay patterns\nStatistical modeling of travel trends and operational dynamics\nData-driven insights into aviation industry performance\n\n\n\nTechnologies Used\n\nSQL\nMySQLWorkbench\nR\nQuarto\nGitHub\nAWS\n\n\n\nSkills Demonstrated\n\nAdvanced data preprocessing and cleaning\nStatistical modeling and hypothesis testing\nInteractive data visualization\nInsight communication through visual storytelling\n\nView Project →\n\n\n\n\nMovie Review Web Application (Binge)\nUniversity of Ottawa - ADM 4379\n\nOverview\nA full-stack web application for browsing and reviewing movies, designed to handle a large database of movie records with optimized performance.\n\n\nKey Features\n\nResponsive user interface for seamless browsing\nSQL database managing 20,000+ movie records\nUser authentication and review submission\nOptimized query performance\n\n\n\nTechnologies Used\n\nFrontend: HTML, CSS, JavaScript\nBackend: PHP\nDatabase: SQL\n\n\n\nKey Achievements\n\nImproved feature response time by 30% through query optimization\nImplemented responsive design for mobile and desktop\nCreated intuitive user experience for movie discovery\n\nView Live Project →\n\n\n\nData Mining Project: Customer Sentiment Analysis\nUniversity of Ottawa - ADM 3308\n\nOverview\nAnalyzed customer reviews to identify sentiment patterns and travel preferences using unsupervised learning techniques.\n\n\nDataset\n\n5,456 Google reviews\nTravel and hospitality domain\nMulti-dimensional customer feedback\n\n\n\nMethodology\n\nApplied K-Means clustering algorithm\nIdentified distinct customer sentiment clusters\nAnalyzed cluster characteristics and patterns\nExtracted actionable insights for content personalization\n\n\n\nKey Findings\n\nDiscovered distinct customer preference segments\nIdentified key factors influencing customer satisfaction\nProvided data-driven recommendations for content strategy\n\n\n\nTechnologies Used\n\nPython\nK-Means Clustering\nNatural Language Processing (NLP)\nData Visualization\n\n\n\nImpact\nThe analysis provided valuable insights into customer preferences, enabling data-driven content personalization strategies and improved targeting of travel services.\n\n\n\nInteractive Dog Adoption Application\nUniversity of Ottawa - ADM 4311\n\nOverview\nA Python-based interactive application built in Jupyter Notebook to facilitate dog adoption and service selection.\n\n\nKey Features\n\nInteractive notebook-based user interface\nSearch and filtering functionality\nAuthentication system\nService options selection\n\n\n\nTechnical Implementation\n\nApplied core Python concepts: loops, functions, conditionals\nImplemented data structures for efficient data management\nBuilt authentication using dictionary-based text mapping\nCreated search algorithms for dog matching\n\n\n\nTechnologies Used\n\nPython\nJupyter Notebook\nData Structures (dictionaries, lists)\n\n\n\nLearning Outcomes\nThis project reinforced fundamental programming concepts and demonstrated the ability to create user-friendly interactive applications using Python.\nView Project Details & Code →"
  },
  {
    "objectID": "projects.html#project-categories",
    "href": "projects.html#project-categories",
    "title": "Projects",
    "section": "Project Categories",
    "text": "Project Categories\n\nProfessional Work\nEnterprise-level automation and data analytics solutions deployed in government settings, focusing on operational efficiency and stakeholder value.\nWeb Development\nFull-stack applications combining frontend design, backend logic, and database management to create functional, user-friendly experiences.\nData Science & Analytics\nMachine learning, statistical analysis, and data mining projects demonstrating analytical thinking and technical expertise.\nPython Applications\nInteractive applications showcasing programming fundamentals and problem-solving capabilities.\n\n← Back to Home View Skills →"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "NKEMDIBE OKWEYE\nLinkedIn | GitHub"
  },
  {
    "objectID": "resume.html#contact-information",
    "href": "resume.html#contact-information",
    "title": "Resume",
    "section": "",
    "text": "NKEMDIBE OKWEYE\nLinkedIn | GitHub"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "Education",
    "text": "Education\n\nMaster of Science in Data Science and Analytics\nGeorgetown University | Washington, DC | 2025 – 2027\nRelevant Coursework: Machine Learning, Statistical Methods, A/B Testing & Experimental Design, Probability & Statistics, Advanced Data Visualization, Database Systems, Python Programming\n\n\nHonours Bachelor of Commerce (Business Technology Management)\nUniversity of Ottawa | Ottawa, Ontario | 2020 – 2025"
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Resume",
    "section": "Skills",
    "text": "Skills\nProgramming & Data Analysis\nPython (Pandas, NumPy, Scikit-learn, PyTorch, NLTK, Matplotlib, Seaborn), SQL, R (tidyverse, ggplot2)\nMachine Learning\nSupervised Learning (Regression, Classification, Logistic Regression, Naive Bayes, KNN), Unsupervised Learning (K-Means, DBSCAN, PCA, t-SNE), Model Evaluation (ROC/AUC, Confusion Matrix, Feature Selection), NLP (Sentiment Analysis, TF-IDF, Topic Modeling)\nExperimentation & Statistics\nA/B Testing, Experimental Design, Statistical Analysis, Bayesian Inference, Hypothesis Testing, Dimensionality Reduction\nData Engineering & Tools\nETL Pipelines, Large-Scale Data Processing, APIs, Git/GitHub, Jupyter Notebooks, AWS, Power BI, Excel, Data Structures & Algorithms"
  },
  {
    "objectID": "resume.html#professional-experience",
    "href": "resume.html#professional-experience",
    "title": "Resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nData Analyst\nDepartment of National Defence | Ottawa, Ontario | September 2023 – August 2024\n\nCollaborated with data engineers and product stakeholders to optimize enterprise datasets for accuracy and scalability, supporting product decisions and departmental reporting for 200+ users\nDesigned and automated Power BI dashboards integrating data from SAP, Excel, Lakehouse, and SharePoint—reducing report generation time by 40% and improving stakeholder decision-making\nUsed SQL in Microsoft Fabric to extract, transform, and load data across Lakehouse environments for real-time reporting\nPartnered with internal clients to identify reporting pain points and translate user needs into intuitive data products, achieving 95% positive feedback on delivered prototypes\nBuilt low-code Power Apps solutions to streamline intake and tracking processes, cutting manual work by 25% and improving workflow visibility\n\n\n\nStudent Analyst\nGlobal Affairs Canada | Ottawa, Ontario | May 2023 – August 2023\n\nSupported internal performance reporting and outreach analytics for international initiatives, validating 3 key policy indicators for management reporting\nConducted competitive and policy gap analyses, aligning insights to organizational objectives and stakeholder needs\nCollaborated cross-functionally with policy and technical teams to define metrics and translate qualitative data into actionable analytics"
  },
  {
    "objectID": "resume.html#projects",
    "href": "resume.html#projects",
    "title": "Resume",
    "section": "Projects",
    "text": "Projects\n\n\n\nMenendez Brothers Media Narrative Analysis\nGeorgetown University - DSAN 5000\n\nEngineered large-scale data pipeline processing 2,840+ documents from multiple APIs (Guardian API, YouTube Data API v3) and historical archives using robust ETL workflows\nDeveloped and evaluated machine learning models (Multinomial Naive Bayes, Logistic Regression) achieving 96.8% test accuracy through hyperparameter tuning and feature selection\nDesigned experiments using unsupervised learning (K-Means, PCA, t-SNE) to reduce 2,000+ TF-IDF features into three interpretable narrative clusters\nApplied statistical analysis and sentiment modeling to quantify temporal trends, identifying 0.4-point sentiment divergence between traditional journalism and social media\nPresented findings through interactive visualizations including ROC curves, confusion matrices, and t-SNE embeddings\n\n\n\n\n\n\nU.S. Airline Performance Analysis\nGeorgetown University - DSAN 6300\n\nDesigned and implemented dimensional data model (fact/dimension tables) for 600,000+ flight records from U.S. Department of Transportation, analyzing operational patterns across airlines and airports using PostgreSQL\nDeveloped complex SQL queries to identify performance anomalies including maximum delays (2,620 minutes), cancellation patterns (14,488 flights), and busiest operational periods (106,575 daily flights)\nConducted statistical analysis and created data visualizations in R (tidyverse, ggplot2, kableExtra) to uncover temporal patterns in flight operations, revealing clear weekday/weekend patterns driven by business travel\n\nView Project →\n\n\n\nRequest Automation Portal\nDepartment of National Defence\nDesigned an automated Azure DevOps workflow integrated with Microsoft Forms and Teams to track 100+ monthly requests; reduced manual entry by 80% and task delays by 50%.\n\n\nMovie Review Web Application (Binge)\nUniversity of Ottawa - ADM 4379\n\nBuilt responsive SQL-backed movie review application managing 20,000+ records with optimized database queries\nImproved feature response time by 30% through query optimization and data structure improvements\nDesigned user-centric interface using HTML, CSS, and PHP to enhance user experience and engagement\n\nView Project →\n\n\nInteractive Dog Adoption Application\nUniversity of Ottawa - ADM 4311\n\nBuilt a Jupyter Notebook–based Python application for dog adoption and service options, executed through interactive notebook cells\nApplied core Python concepts (loops, functions, conditionals, and data structures) to build search and selection features\nDeveloped a simple authentication system using dictionary-based text mapping to validate usernames and passwords\n\n\n\nData Mining Project\nUniversity of Ottawa - ADM 3308\nIdentified key customer sentiment clusters from 5,456 Google reviews using K-Means analysis to uncover travel preference insights and inform content personalization strategies."
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "Technical Skills",
    "text": "Technical Skills\nProgramming & Development\nPython (Pandas, NumPy, Scikit-learn, PyTorch, NLTK), R (tidyverse, ggplot), SQL, HTML, CSS, JavaScript, Git/GitHub, OOP\nCloud & Infrastructure\nAWS, Azure DevOps, Microsoft Fabric, CLI\nBusiness Intelligence & Automation\nPower BI, Power Apps, Power Automate, Dataflow Gen2, Excel, SAP\nAnalytics & Data Science\nETL, Statistical Analysis, Data Mining, Data Engineering, Data Visualization, A/B Testing, Bayesian Inference, Supervised & Unsupervised Learning (regression, classification, t-SNE, PCA, DBSCAN, K-Means), Experimental Design, NLP, Big Data\nMarketing & Digital\nA/B Testing, Digital Marketing, Social Media Analytics, SEO/SEM, Web Design\n← Back to Home View Skills →"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nkem Okweye",
    "section": "",
    "text": "Welcome to my portfolio. I’m a data professional passionate about transforming complex data into actionable insights and building innovative solutions that drive business value.\nView Projects Resume"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Nkem Okweye",
    "section": "About Me",
    "text": "About Me\n\n\n\n\n\nI’m currently pursuing a Master of Science in Data Science and Analytics at Georgetown University, building on my Honours Bachelor of Commerce in Business Technology Management from the University of Ottawa.\nWith professional experience as a Data Analyst at the Department of National Defence and as a Student Analyst at Global Affairs Canada, I’ve developed expertise in building scalable data solutions, automating reporting workflows, and translating complex business requirements into intuitive data products.\nI specialize in leveraging modern data tools and technologies to solve real-world problems, from designing Power BI dashboards that reduce reporting time by 40% to building automated workflows that cut manual work by 80%."
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Nkem Okweye",
    "section": "Featured Projects",
    "text": "Featured Projects\n\n\n\n\nThe Menendez Brothers: From Courtrooms to Comments Sections\nGeorgetown University\nA data science exploration tracing how public discourse around the Menendez brothers transformed across 35 years—from their 1989 crime through their sensationalized trials to the Netflix era. This project analyzes media narratives across multiple platforms, revealing fundamental shifts in how American society understands family violence, male victimization, and criminal justice reform.\nTechnologies: Python, NLP, Text Analysis, Data Visualization, Social Media Analytics\nView Project →\n\n\n\n\n\nA Deep Dive into U.S. Airline Performance\nGeorgetown University\nAn immersive exploration of aviation data, uncovering hidden patterns in flight operations, delays, and travel trends through statistical modeling and interactive visualizations. This project transforms thousands of flight records into actionable insights about air travel dynamics.\nTechnologies: SQL, MySQLWorkbench, R, Quarto, GitHub, AWS\nView Project →\n\n\n\nRequest Automation Portal\nDepartment of National Defence\nDesigned an automated Azure DevOps workflow integrated with Microsoft Forms and Teams to track 100+ monthly requests, reducing manual entry by 80% and task delays by 50%.\nTechnologies: Azure DevOps, Microsoft Forms, Power Automate, Teams\n\n\nData Mining Project\nUniversity of Ottawa\nIdentified key customer sentiment clusters from 5,456 Google reviews using K-Means analysis to uncover travel preference insights and inform content personalization strategies.\nTechnologies: Python, K-Means, Clustering, NLP\n\n\nMovie Review Application (Binge)\nUniversity of Ottawa\nBuilt a responsive SQL-backed movie review application for 20,000+ records using HTML, CSS, and PHP, optimizing queries and user experience to improve feature response by 30%.\nTechnologies: SQL, HTML, CSS, PHP\nView Project →\n\n\nInteractive Dog Adoption Application\nUniversity of Ottawa\nBuilt a Jupyter Notebook-based Python application for dog adoption and service options with authentication and search features using core Python concepts.\nTechnologies: Python, Jupyter, Data Structures\nView Project →"
  },
  {
    "objectID": "index.html#skills-snapshot",
    "href": "index.html#skills-snapshot",
    "title": "Nkem Okweye",
    "section": "Skills Snapshot",
    "text": "Skills Snapshot\n\n\nProgramming & Tools\nPython, R, SQL, JavaScript, HTML/CSS, Git, AWS, Azure DevOps\n\n\nAnalytics & Data Science\nETL, Statistical Analysis, Machine Learning, NLP, Data Visualization, A/B Testing\n\n\nBusiness Intelligence\nPower BI, Power Apps, Power Automate, Excel, SAP, Dataflow Gen2\n\n\nView Full Skills →"
  },
  {
    "objectID": "index.html#lets-connect",
    "href": "index.html#lets-connect",
    "title": "Nkem Okweye",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’m always interested in discussing data science, analytics, and technology. Feel free to reach out!\nView Full Resume →"
  },
  {
    "objectID": "skills.html",
    "href": "skills.html",
    "title": "Skills & Expertise",
    "section": "",
    "text": "← Back to Home"
  },
  {
    "objectID": "skills.html#core-technical-skills",
    "href": "skills.html#core-technical-skills",
    "title": "Skills & Expertise",
    "section": " Core Technical Skills",
    "text": "Core Technical Skills\n\n\n Python\nMy go-to for data analysis, machine learning, and automation. From building NLP pipelines to clustering 5,000+ reviews, Python is my data science workhorse.\nKey Libraries: Pandas • NumPy • Scikit-learn • PyTorch • NLTK\n\n\n R\nStatistical analysis and data visualization specialist. Used for advanced analytics and creating publication-ready visualizations.\nKey Packages: tidyverse • ggplot2 • statistical modeling\n\n\n SQL\nDatabase design and query optimization for handling 20,000+ record datasets. Experience with MySQL and cloud-based data warehousing.\nApplications: Query optimization • Database design • ETL processes\n\n\n Web Development\nFull-stack capabilities for building responsive applications and data-driven web tools.\nTechnologies: HTML • CSS • JavaScript • PHP • Git/GitHub"
  },
  {
    "objectID": "skills.html#microsoft-power-platform",
    "href": "skills.html#microsoft-power-platform",
    "title": "Skills & Expertise",
    "section": " Microsoft Power Platform",
    "text": "Microsoft Power Platform\n\n\n Power BI\nDesigned dashboards that reduced reporting time by 40% and served 200+ users across departments.\n\nAdvanced DAX formulas\nData modeling & relationships\nInteractive dashboard design\nPerformance optimization\n\n\n\n Power Automate\nBuilt automation workflows that cut manual work by 80% and integrated with Azure DevOps for seamless request tracking.\n\nWorkflow automation\nTeams integration\nForms-to-database pipelines\n\n\n\n Power Apps\nLow-code application development for rapid prototyping and business solutions.\n\nCanvas apps\nModel-driven apps\nCustom connectors\n\n\n\n Microsoft Fabric\nWorking with Dataflow Gen2, Lakehouse architecture, and modern data engineering practices.\n\nDataflow Gen2\nLakehouse design\nETL pipelines"
  },
  {
    "objectID": "skills.html#cloud-devops",
    "href": "skills.html#cloud-devops",
    "title": "Skills & Expertise",
    "section": " Cloud & DevOps",
    "text": "Cloud & DevOps\n\n\n AWS\nCloud infrastructure, deployment, and data storage solutions.\n\n\n Azure\nAzure DevOps for project management and CI/CD workflows.\n\n\n Version Control\nGit/GitHub for collaborative development and code management."
  },
  {
    "objectID": "skills.html#data-science-machine-learning",
    "href": "skills.html#data-science-machine-learning",
    "title": "Skills & Expertise",
    "section": " Data Science & Machine Learning",
    "text": "Data Science & Machine Learning\n\n\n Data Engineering\n\nETL pipeline design\nData warehousing\nDatabase architecture\nData mining at scale\n\n\n\n Statistical Analysis\n\nBayesian inference\nA/B testing & experimentation\nExperimental design\nHypothesis testing\n\n\n\n Machine Learning\nSupervised Learning - Regression & classification - Model evaluation & tuning\nUnsupervised Learning - K-Means & DBSCAN clustering - PCA & t-SNE - Pattern discovery\n\n\n Specialized Techniques\n\nNatural Language Processing\nBig data processing\nAdvanced data visualization\nSocial media analytics"
  },
  {
    "objectID": "skills.html#soft-skills-that-drive-impact",
    "href": "skills.html#soft-skills-that-drive-impact",
    "title": "Skills & Expertise",
    "section": " Soft Skills That Drive Impact",
    "text": "Soft Skills That Drive Impact\n\n\n Stakeholder Management\nSuccessfully collaborated with 200+ users across departments, translating technical solutions into business value.\n\n\n Problem Solving\nIdentifying pain points and designing data-driven solutions—from automation portals to predictive models.\n\n\n Communication\nPresenting complex technical concepts to non-technical audiences through clear visualizations and storytelling.\n\n\n Cross-functional Collaboration\nWorking seamlessly with data engineers, policy teams, and business stakeholders to deliver integrated solutions."
  },
  {
    "objectID": "skills.html#want-to-see-these-skills-in-action",
    "href": "skills.html#want-to-see-these-skills-in-action",
    "title": "Skills & Expertise",
    "section": "Want to see these skills in action?",
    "text": "Want to see these skills in action?\nExplore My Projects View Resume"
  }
]